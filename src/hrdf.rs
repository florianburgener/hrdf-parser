use std::{
    error::Error,
    fs::{self, File},
    io::{BufReader, Cursor},
    path::Path,
    time::Instant,
};

use crate::{models::Version, storage::DataStorage};
use log::info;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use url::Url;
use zip::ZipArchive;

#[derive(Debug, Serialize, Deserialize)]
pub struct Hrdf {
    data_storage: DataStorage,
}

impl Hrdf {
    /// Loads and parses the data.<br>
    /// If an URL is provided, the HRDF archive (ZIP file) is downloaded automatically. If a path is provided, it must absolutely point to an HRDF archive (ZIP file).<br>
    /// The ZIP archive is automatically decompressed into the /tmp folder.
    pub async fn new(
        version: Version,
        url_or_path: &str,
        force_rebuild_cache: bool,
    ) -> Result<Self, Box<dyn Error>> {
        let now = Instant::now();

        let unique_filename = format!("{:x}", Sha256::digest(url_or_path.as_bytes()));
        let cache_path = format!("{unique_filename}.cache");

        let hrdf = if Path::new(&cache_path).exists() && !force_rebuild_cache {
            // Loading from cache.
            info!("Reading from cache file {cache_path}...");

            // If loading from cache fails, None is returned.
            Hrdf::load_from_cache(&cache_path).ok()
        } else {
            // No loading from cache.
            None
        };

        let hrdf = if let Some(hrdf) = hrdf {
            // The cache has been loaded without error.
            hrdf
        } else {
            // The cache must be built.
            // If cache loading has failed, the cache must be rebuilt.
            let compressed_data_path = if Url::parse(url_or_path).is_ok() {
                let compressed_data_path = format!("/tmp/{unique_filename}.zip");

                if !Path::new(&compressed_data_path).exists() {
                    // The data must be downloaded.
                    info!("Downloading data into {compressed_data_path}...");
                    let response = reqwest::get(url_or_path).await?;
                    let mut file = std::fs::File::create(&compressed_data_path)?;
                    let mut content = Cursor::new(response.bytes().await?);
                    std::io::copy(&mut content, &mut file)?;
                }

                compressed_data_path
            } else {
                url_or_path.to_string()
            };

            let decompressed_data_path = format!("/tmp/{unique_filename}");

            if !Path::new(&decompressed_data_path).exists() {
                // The data must be decompressed.
                info!("Unzipping archive into {decompressed_data_path}...");
                let file = File::open(&compressed_data_path)?;
                let mut archive = ZipArchive::new(BufReader::new(file))?;
                archive.extract(&decompressed_data_path)?;
            }

            info!("{decompressed_data_path}");
            info!("Building cache...");

            let hrdf = Self {
                data_storage: DataStorage::new(version, &decompressed_data_path)?,
            };

            hrdf.build_cache(&cache_path)?;
            hrdf
        };

        let elapsed = now.elapsed();

        info!("Hrdf data loaded: {:.2?}", elapsed);

        Ok(hrdf)
    }

    // Getters/Setters

    pub fn data_storage(&self) -> &DataStorage {
        &self.data_storage
    }

    // Functions

    pub fn build_cache(&self, path: &str) -> Result<(), Box<dyn Error>> {
        let data = bincode::serialize(&self)?;
        fs::write(path, data)?;
        Ok(())
    }

    pub fn load_from_cache(path: &str) -> Result<Self, Box<dyn Error>> {
        let data = fs::read(path)?;
        let hrdf: Self = bincode::deserialize(&data)?;
        Ok(hrdf)
    }
}
